{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN(인공신경망)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "# layers는 계층을 만드는 모듈\n",
    "# models는 layer들의 연결, 신경망모델생성, 컴파일, 학습\n",
    "# models.Model객체에서 딥러닝 처리함수를 제공\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2단계\n",
    "파라미턴 설정  -입력계층노드수, 은닉계층노드수, 출력값이가질클래스수, 출력노드 수\n",
    "            - Nin, Nh, number_of_class, Nout\n",
    "            \n",
    " 3단계 모델링           \n",
    " - 가장 기본이 되는 구조\n",
    " - 연쇄방식 : 복잡도가 높은 모델에 적용하기는 한계\n",
    " - 분산방식\n",
    " - 함수형과 객체지향형\n",
    "  \n",
    " -분산 함수\n",
    " -연쇄 함수\n",
    " -분산 객체\n",
    " -연쇄 객체\n",
    " \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "\n",
    "def ANN_models_func(Nin, Nh, Nout):\n",
    "    x = layers.Input(shape=(Nin,)) #신경망 구조 지정\n",
    "                                    # 입력계층 layers.Input함수로 지정\n",
    "                                    # 원소 Nin개를 가지는 입력 신호 벡터\n",
    "    h = layers.Activation('relu')(layers.Dense(Nh)(x))\n",
    "        #은닉 계층의 구조와 수\n",
    "        #layers.Dense로 은닉계층 지정 , 노드가 Nh개인 경우\n",
    "        #x를 입력으로 받아들이는  입력 노드\n",
    "        #layers.Dense(Nh)는 layers.Dense객체의 인스턴스이다.\n",
    "        #활서화 함수 layers.Activation('relu')\n",
    "        #tanH()나 simoid()보다 많이 상용된다.\n",
    "        #은닉계층의 각노드들은 ReLU로 활성화 처리한뒤에 다음 계층으로\n",
    "        \n",
    "        \n",
    "    y = layers.Activation('softmax')(layers.Dense(Nout)(h))\n",
    "    #출력계층\n",
    "    #출력노드의 수는 Nout로 지정\n",
    "    #은닉노드의 출력값 h를 출력노드의 입력정보로 사용\n",
    "    #분류의 경우 출력노드의 활성화 함수로 소프트맥스\n",
    "    \n",
    "    #layers.Activation 계층을 합쳐서 인공지능 모델을 만듬\n",
    "    \n",
    "    model = models.Model(x, y) #Model은 여려가지 필요한 함수와 연계되도록 만듬\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #컴파일 과정\n",
    "    #loss 손실함수를 지정\n",
    "    #optimizer은 최적화 함수 지정\n",
    "    #metrics는 손실뿐아닌 정확도도 측정하라\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연쇄 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_seq_func(Nin, Nh, Nout):\n",
    "    model = models.Sequential() #분산방식과 다를게 모델 먼저 설정\n",
    "                                #모델의초기화\n",
    "        \n",
    "    model.add(layers.Dense(Nh, activation='relu', input_shape=(Nin,))) #모델구조설정\n",
    "                                #입력계층과 은닉계층의 형태가 동시에 정해짐\n",
    "                                #입력노드 Nin개는 완전 연결 계층 Nh개로 구성된 은닉계층으로\n",
    "                                # 이 은닉 계층의 노드들은 ReLU를활성화 함수로 사용\n",
    "                \n",
    "    model.add(layers.Dense(Nout, activation='softmax'))#모델구조설정\n",
    "    #은닉 계층의 출력은 출력이 Nout개인 출력 노드로 보내짐\n",
    "    #추가되는 계층을 기술할때 add()를 이용해 계속 더해주며 된다.\n",
    "    #그러나 복잡하면 분산방식 모델링 사용해야함\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  분산 객체지향형\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_models_class(models.Model): #model.Model로 부터 특성 상속\n",
    "                                    #model.Model 학습, 예측, 평가와 같은 다양한 함수 제공\n",
    "    def __init__(self, Nin, Nh, Nout): #초기화함수 정의\n",
    "                    # 입력,  은닉, 출력계층의 노드 수를 받는다.\n",
    "            \n",
    "            \n",
    "        # Prepare network layers and activate functions\n",
    "        hidden = layers.Dense(Nh) #은닉계층이 하나이므로 은닉의 출려도 한개\n",
    "        #hidden_l = [layers.Dense(n) for n in Nh_l] # 단일문장\n",
    "        #hidden_l = []  # 이하 여러문장\n",
    "        #for n in Nh_l\n",
    "            #hidden_l.append(layers.Dense(n))\n",
    "            \n",
    "        output = layers.Dense(Nout) #노드 수가 Nout개인 출력 계층을 정의\n",
    "                                    #모델을 구성하는 요소로 사용됨\n",
    "            \n",
    "        relu = layers.Activation('relu') #비선형을 넣어준다.\n",
    "        softmax = layers.Activation('softmax') #분류의 경우 사용\n",
    "        #위 함수 2개는 계산 모듈이므로 한 번 정의해두면 모델내에서 여러번 사용할수 있따.\n",
    "        \n",
    "        # Connect network elements\n",
    "        x = layers.Input(shape=(Nin,))\n",
    "        h = relu(hidden(x))\n",
    "        y = softmax(output(h))\n",
    "\n",
    "        super().__init__(x, y) #상속받은 부모 클래스의 초기화 진행\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  연쇄 객체지향형\n",
    " - 클래스 없이 기본형태로 구성할때는 신경망 모델이 연속적인 하나의 고리로 연결되어 있다는 가정하에 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_seq_class(models.Sequential): #models.Sequential에서 상속\n",
    "    def __init__(self, Nin, Nh, Nout):\n",
    "        super().__init__() #부모 클래스의 초기화 함수를 자신의 초기화함수 가장 앞 단에서 부름\n",
    "        self.add(layers.Dense(Nh, activation='relu', input_shape=(Nin,)))        \n",
    "        #앞단의 계층에 새로운 계층을 계속 추가하는 형태\n",
    "        #입력계층의 노드 수 Nin\n",
    "        \n",
    "        self.add(layers.Dense(Nout, activation='softmax'))#출력계층의 정의 , 노드 Nout개, 활성화SM\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 활용도에 따라 3가지\n",
    "\n",
    "### 학습, 검증, 평가 데이터\n",
    "학습 : 모델학습\n",
    "검증 : 학습시 성능 검증(학습데이터안에서 일정비율로 추출, 혹은 바로 평가데이터 직접 사용)\n",
    "평가 : 학습후 모델 성능 평가\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  #reshape()\n",
    "from keras import datasets  # mnist()\n",
    "from keras.utils import np_utils  # to_categorical()\n",
    "\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train) #0과1로 표현되는 백테 10개로 바꿈\n",
    "    Y_test = np_utils.to_categorical(y_test)   #0과1로 표현되는 백테 10개로 바꿈\n",
    "    #분류작업 시 정수보다 이진 벡터로 출력 변수구성이 효율적\n",
    "    \n",
    "\n",
    "    #아래 3줄은 실습 및 평가용 데이터를 3차원에서 2차원으로 조정\n",
    "    L, W, H = X_train.shape #멤버변수 shape에는 2D 이미지데이터를 저장하는 저장소 규격이 들이있다.\n",
    "    X_train = X_train.reshape(-1, W * H) #벡터 이미지 혀태로 바꾸어야 한다.\n",
    "    X_test = X_test.reshape(-1, W * H) #-1:행렬의행을자동설정, 전체 운소수에서 W*H 자동으로 나눠줌\n",
    "\n",
    "    X_train = X_train / 255.0 #ANN의 최적화를 위해 아규먼트를 정규화함\n",
    "    X_test = X_test / 255.0 #결국 0 ~ 1사이의 실수로 바꾼다.\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN학습 결과 그래프 구현\n",
    "분석한 결과를 바탕으로 바른 학습인지\n",
    "하이퍼파라미터를 어떻게 조절하는지\n",
    "하이퍼파라미터는 학습 전에 사람이 지정해주어야 하는 변수\n",
    "측정한 손실과\n",
    "정확도의 추이를 관찰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN구조와상관없이 다른 신경마에서도 이함수들을 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_acc(history, title=None):  #정확도를 그리는 함수\n",
    "    # summarize history for accuracy\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Verification'], loc=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history, title=None): #손실을 그리는 함수\n",
    "    # summarize history for loss\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['loss']) # 선 그리기 #history에 들어있는 실제 학습 데이터로 구한 손실값\n",
    "    plt.plot(history['val_loss'])       #학습 데이터 일부를 사용한 검증 데이터로 구한 손실값\n",
    "    if title is not None:\n",
    "        plt.title(title) #그래프 제목 표시\n",
    "    plt.ylabel('Loss')  #X축이름표시\n",
    "    plt.xlabel('Epoch') #Y축이름표시\n",
    "    plt.legend(['Training', 'Verification'], loc=0) #각 라인의 표식 표시\n",
    "    # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Nin = 784 #입력 길이가 784인 데이터\n",
    "    Nh = 100 #은닉계층의 노드수를 100d으로\n",
    "    number_of_class = 10 # 분류할 데이터 클래스 수와 같다.\n",
    "    Nout = number_of_class\n",
    "\n",
    "    #model = ANN_models_func(Nin, Nh, Nout)\n",
    "    model = ANN_models_class(Nin, Nh, Nout)\n",
    "    # model = ANN_seq_class(Nin, Nh, Nout)  #모델인스턴스 만들고\n",
    "    (X_train, Y_train), (X_test, Y_test) = Data_func() #데이터 불러오기\n",
    "\n",
    "    ##############################################\n",
    "    # Training\n",
    "    ##############################################\n",
    "    history = model.fit(X_train, Y_train, epochs=5, batch_size=100, validation_split=0.2)\n",
    "    #학습 진행상황을 변수 history에 저장\n",
    "    # batch_size는 한데이터를얼마씩나눠서 넣을지를 지정\n",
    "    # validation_split 전체학습데이터 중에서학습진행중 성능검증에 데이터를얼마나사용할지를결정하는변수입니다. \n",
    "    # 학습데이터의20%를성능검증에활용\n",
    "    \n",
    "    performace_test = model.evaluate(X_test, Y_test, batch_size=100)\n",
    "    print('Test Loss and Accuracy ->', performace_test)\n",
    "\n",
    "    #plot_loss(history)\n",
    "    #plt.show()\n",
    "    #plot_acc(history)\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "# Run code\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
