{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN(인공신경망)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "# layers는 계층을 만드는 모듈\n",
    "# models는 layer들의 연결, 신경망모델생성, 컴파일, 학습\n",
    "# models.Model객체에서 딥러닝 처리함수를 제공\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 활용도에 따라 3가지\n",
    "\n",
    "### 학습, 검증, 평가 데이터\n",
    "학습 : 모델학습\n",
    "검증 : 학습시 성능 검증(학습데이터안에서 일정비율로 추출, 혹은 바로 평가데이터 직접 사용)\n",
    "평가 : 학습후 모델 성능 평가\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  #reshape()\n",
    "from keras import datasets  # mnist()\n",
    "from keras.utils import np_utils  # to_categorical()\n",
    "\n",
    "\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train) #0과1로 표현되는 백테 10개로 바꿈\n",
    "    Y_test = np_utils.to_categorical(y_test)   #0과1로 표현되는 백테 10개로 바꿈\n",
    "    #분류작업 시 정수보다 이진 벡터로 출력 변수구성이 효율적\n",
    "    \n",
    "\n",
    "    #아래 3줄은 실습 및 평가용 데이터를 3차원에서 2차원으로 조정\n",
    "    L, W, H = X_train.shape #멤버변수 shape에는 2D 이미지데이터를 저장하는 저장소 규격이 들이있다.\n",
    "    X_train = X_train.reshape(-1, W * H) #벡터 이미지 혀태로 바꾸어야 한다.\n",
    "    X_test = X_test.reshape(-1, W * H) #-1:행렬의행을자동설정, 전체 운소수에서 W*H 자동으로 나눠줌\n",
    "\n",
    "    X_train = X_train / 255.0 #ANN의 최적화를 위해 아규먼트를 정규화함\n",
    "    X_test = X_test / 255.0 #결국 0 ~ 1사이의 실수로 바꾼다.\n",
    "\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN학습 결과 그래프 구현\n",
    "분석한 결과를 바탕으로 바른 학습인지\n",
    "하이퍼파라미터를 어떻게 조절하는지\n",
    "하이퍼파라미터는 학습 전에 사람이 지정해주어야 하는 변수\n",
    "측정한 손실과\n",
    "정확도의 추이를 관찰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN구조와상관없이 다른 신경마에서도 이함수들을 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_acc(history, title=None):  #정확도를 그리는 함수\n",
    "    # summarize history for accuracy\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Verification'], loc=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history, title=None): #손실을 그리는 함수\n",
    "    # summarize history for loss\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['loss']) # 선 그리기 #history에 들어있는 실제 학습 데이터로 구한 손실값\n",
    "    plt.plot(history['val_loss'])       #학습 데이터 일부를 사용한 검증 데이터로 구한 손실값\n",
    "    if title is not None:\n",
    "        plt.title(title) #그래프 제목 표시\n",
    "    plt.ylabel('Loss')  #X축이름표시\n",
    "    plt.xlabel('Epoch') #Y축이름표시\n",
    "    plt.legend(['Training', 'Verification'], loc=0) #각 라인의 표식 표시\n",
    "    # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_models_class(models.Model): #model.Model로 부터 특성 상속\n",
    "                                    #model.Model 학습, 예측, 평가와 같은 다양한 함수 제공\n",
    "    def __init__(self, Nin, Nh, Nout): #초기화함수 정의\n",
    "                    # 입력,  은닉, 출력계층의 노드 수를 받는다.\n",
    "            \n",
    "            \n",
    "        # Prepare network layers and activate functions\n",
    "        hidden = layers.Dense(Nh) #은닉계층이 하나이므로 은닉의 출려도 한개\n",
    "        #hidden_l = [layers.Dense(n) for n in Nh_l] # 단일문장\n",
    "        #hidden_l = []  # 이하 여러문장\n",
    "        #for n in Nh_l\n",
    "            #hidden_l.append(layers.Dense(n))\n",
    "            \n",
    "        output = layers.Dense(Nout) #노드 수가 Nout개인 출력 계층을 정의\n",
    "                                    #모델을 구성하는 요소로 사용됨\n",
    "            \n",
    "        relu = layers.Activation('relu') #비선형을 넣어준다.\n",
    "        softmax = layers.Activation('softmax') #분류의 경우 사용\n",
    "        #위 함수 2개는 계산 모듈이므로 한 번 정의해두면 모델내에서 여러번 사용할수 있따.\n",
    "        \n",
    "        # Connect network elements\n",
    "        x = layers.Input(shape=(Nin,))\n",
    "        h = relu(hidden(x))\n",
    "        y = softmax(output(h))\n",
    "\n",
    "        super().__init__(x, y) #상속받은 부모 클래스의 초기화 진행\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 1s 15us/step - loss: 0.4047 - accuracy: 0.8889 - val_loss: 0.2172 - val_accuracy: 0.9417\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1939 - accuracy: 0.9445 - val_loss: 0.1627 - val_accuracy: 0.9536\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1431 - accuracy: 0.9593 - val_loss: 0.1335 - val_accuracy: 0.9617\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.1113 - accuracy: 0.9681 - val_loss: 0.1178 - val_accuracy: 0.9650\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.0914 - accuracy: 0.9736 - val_loss: 0.1124 - val_accuracy: 0.9663\n",
      "10000/10000 [==============================] - 0s 5us/step\n",
      "Test Loss and Accuracy -> [0.10729601367842406, 0.968500018119812]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    Nin = 784 #입력 길이가 784인 데이터\n",
    "    Nh = 100 #은닉계층의 노드수를 100d으로\n",
    "    number_of_class = 10 # 분류할 데이터 클래스 수와 같다.\n",
    "    Nout = number_of_class\n",
    "\n",
    "    #model = ANN_models_func(Nin, Nh, Nout)\n",
    "    model = ANN_models_class(Nin, Nh, Nout)\n",
    "    # model = ANN_seq_class(Nin, Nh, Nout)  #모델인스턴스 만들고\n",
    "    (X_train, Y_train), (X_test, Y_test) = Data_func() #데이터 불러오기\n",
    "\n",
    "    ##############################################\n",
    "    # Training\n",
    "    ##############################################\n",
    "    history = model.fit(X_train, Y_train, epochs=5, batch_size=100, validation_split=0.2)\n",
    "    #학습 진행상황을 변수 history에 저장\n",
    "    # batch_size는 한데이터를얼마씩나눠서 넣을지를 지정\n",
    "    # validation_split 전체학습데이터 중에서학습진행중 성능검증에 데이터를얼마나사용할지를결정하는변수입니다. \n",
    "    # 학습데이터의20%를성능검증에활용\n",
    "    \n",
    "    performace_test = model.evaluate(X_test, Y_test, batch_size=100)\n",
    "    print('Test Loss and Accuracy ->', performace_test)\n",
    "\n",
    "    #plot_loss(history)\n",
    "    #plt.show()\n",
    "    #plot_acc(history)\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "# Run code\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
